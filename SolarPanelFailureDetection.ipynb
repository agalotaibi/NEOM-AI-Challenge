{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "knB7EtroImNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpSTOCp3Iwhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = '/content/drive/My Drive/Solar'\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/val'\n",
        "test_dir = data_dir + '/test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBJa0cOwI4LU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                          transforms.RandomResizedCrop(192),\n",
        "                                          transforms.RandomHorizontalFlip(),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                               [0.229, 0.224, 0.225])])\n",
        "\n",
        "validation_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                            transforms.CenterCrop(192),\n",
        "                                            transforms.ToTensor(),\n",
        "                                            transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                                 [0.229, 0.224, 0.225])])\n",
        "\n",
        "testing_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                         transforms.CenterCrop(192),\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                              [0.229, 0.224, 0.225])])\n",
        "\n",
        "# TODO: Load the datasets with ImageFolder\n",
        "training_dataset = datasets.ImageFolder(train_dir, transform=training_transforms)\n",
        "validation_dataset = datasets.ImageFolder(valid_dir, transform=validation_transforms)\n",
        "testing_dataset = datasets.ImageFolder(test_dir, transform=testing_transforms)\n",
        "\n",
        "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=64, shuffle=True)\n",
        "validate_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=32)\n",
        "test_loader = torch.utils.data.DataLoader(testing_dataset, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPvkpFNmKa0n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "41e1b19d-2322-41e0-8363-ecc613e2c67b"
      },
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I79DBzHZKby4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for parameter in model.parameters():\n",
        "    parameter.requires_grad = False\n",
        "\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "# Build custom classifier\n",
        "classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(25088, 5000)),\n",
        "                                        ('relu', nn.ReLU()),\n",
        "                                        ('drop', nn.Dropout(p=0.5)),\n",
        "                                        ('fc2', nn.Linear(5000, 102)),\n",
        "                                        ('output', nn.LogSoftmax(dim=1))]))\n",
        "\n",
        "model.classifier = classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnU2jifLKfxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation(model, validateloader, criterion):\n",
        "    \n",
        "    val_loss = 0\n",
        "    accuracy = 0\n",
        "    \n",
        "    for images, labels in iter(validateloader):\n",
        "\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "        output = model.forward(images)\n",
        "        val_loss += criterion(output, labels).item()\n",
        "\n",
        "        probabilities = torch.exp(output)\n",
        "        \n",
        "        equality = (labels.data == probabilities.max(dim=1)[1])\n",
        "        accuracy += equality.type(torch.FloatTensor).mean()\n",
        "    \n",
        "    return val_loss, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioimN3TtKik1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.NLLLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KdNurEoKlAa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "ac59dd94-789f-4a19-c951-69fbd4c25a6a"
      },
      "source": [
        "\n",
        "\n",
        "def train_classifier():\n",
        "\n",
        "    \n",
        "\n",
        "        epochs = 7\n",
        "        steps = 0\n",
        "        print_every = 100\n",
        "\n",
        "        model.to('cuda')\n",
        "\n",
        "        for e in range(epochs):\n",
        "        \n",
        "            model.train()\n",
        "    \n",
        "            running_loss = 0\n",
        "    \n",
        "            for images, labels in iter(train_loader):\n",
        "        \n",
        "                steps += 1\n",
        "        \n",
        "                images, labels = images.to('cuda'), labels.to('cuda')\n",
        "        \n",
        "                optimizer.zero_grad()\n",
        "        \n",
        "                output = model.forward(images)\n",
        "                loss = criterion(output, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "        \n",
        "                running_loss += loss.item()\n",
        "        \n",
        "                if steps % print_every == 0:\n",
        "                \n",
        "                    model.eval()\n",
        "                \n",
        "                    # Turn off gradients for validation, saves memory and computations\n",
        "                    with torch.no_grad():\n",
        "                        validation_loss, accuracy = validation(model, validate_loader, criterion)\n",
        "            \n",
        "                    print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "                          \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
        "                          \"Validation Loss: {:.3f}.. \".format(validation_loss/len(validate_loader)),\n",
        "                          \"Validation Accuracy: {:.3f}\".format(accuracy/len(validate_loader)))\n",
        "            \n",
        "                    running_loss = 0\n",
        "                    model.train()\n",
        "                    \n",
        "train_classifier()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/7..  Training Loss: 2.184..  Validation Loss: 0.118..  Validation Accuracy: 0.956\n",
            "Epoch: 1/7..  Training Loss: 0.204..  Validation Loss: 0.084..  Validation Accuracy: 0.957\n",
            "Epoch: 1/7..  Training Loss: 0.157..  Validation Loss: 0.182..  Validation Accuracy: 0.926\n",
            "Epoch: 2/7..  Training Loss: 0.102..  Validation Loss: 0.062..  Validation Accuracy: 0.973\n",
            "Epoch: 2/7..  Training Loss: 0.153..  Validation Loss: 0.058..  Validation Accuracy: 0.980\n",
            "Epoch: 2/7..  Training Loss: 0.164..  Validation Loss: 0.050..  Validation Accuracy: 0.984\n",
            "Epoch: 3/7..  Training Loss: 0.045..  Validation Loss: 0.175..  Validation Accuracy: 0.933\n",
            "Epoch: 3/7..  Training Loss: 0.163..  Validation Loss: 0.050..  Validation Accuracy: 0.983\n",
            "Epoch: 3/7..  Training Loss: 0.154..  Validation Loss: 0.127..  Validation Accuracy: 0.937\n",
            "Epoch: 3/7..  Training Loss: 0.170..  Validation Loss: 0.086..  Validation Accuracy: 0.951\n",
            "Epoch: 4/7..  Training Loss: 0.167..  Validation Loss: 0.055..  Validation Accuracy: 0.978\n",
            "Epoch: 4/7..  Training Loss: 0.161..  Validation Loss: 0.206..  Validation Accuracy: 0.930\n",
            "Epoch: 4/7..  Training Loss: 0.155..  Validation Loss: 0.055..  Validation Accuracy: 0.979\n",
            "Epoch: 5/7..  Training Loss: 0.114..  Validation Loss: 0.117..  Validation Accuracy: 0.938\n",
            "Epoch: 5/7..  Training Loss: 0.161..  Validation Loss: 0.087..  Validation Accuracy: 0.951\n",
            "Epoch: 5/7..  Training Loss: 0.171..  Validation Loss: 0.044..  Validation Accuracy: 0.987\n",
            "Epoch: 6/7..  Training Loss: 0.047..  Validation Loss: 0.349..  Validation Accuracy: 0.919\n",
            "Epoch: 6/7..  Training Loss: 0.181..  Validation Loss: 0.045..  Validation Accuracy: 0.985\n",
            "Epoch: 6/7..  Training Loss: 0.154..  Validation Loss: 0.051..  Validation Accuracy: 0.978\n",
            "Epoch: 6/7..  Training Loss: 0.147..  Validation Loss: 0.074..  Validation Accuracy: 0.971\n",
            "Epoch: 7/7..  Training Loss: 0.148..  Validation Loss: 0.045..  Validation Accuracy: 0.984\n",
            "Epoch: 7/7..  Training Loss: 0.146..  Validation Loss: 0.045..  Validation Accuracy: 0.987\n",
            "Epoch: 7/7..  Training Loss: 0.137..  Validation Loss: 0.068..  Validation Accuracy: 0.976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrG2ieJyKomT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62a75433-dd1f-42c6-bf6b-05419acc125c"
      },
      "source": [
        "def test_accuracy(model, test_loader):\n",
        "\n",
        "    # Do validation on the test set\n",
        "     model.eval()\n",
        "     model.to('cuda')\n",
        "\n",
        "     with torch.no_grad():\n",
        "    \n",
        "        accuracy = 0\n",
        "    \n",
        "        for images, labels in iter(test_loader):\n",
        "    \n",
        "            images, labels = images.to('cuda'), labels.to('cuda')\n",
        "    \n",
        "            output = model.forward(images)\n",
        "\n",
        "            probabilities = torch.exp(output)\n",
        "        \n",
        "            equality = (labels.data == probabilities.max(dim=1)[1])\n",
        "        \n",
        "            accuracy += equality.type(torch.FloatTensor).mean()\n",
        "        \n",
        "        print(\"Test Accuracy: {}\".format(accuracy/len(test_loader)))    \n",
        "        \n",
        "        \n",
        "test_accuracy(model, test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9554570913314819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1V-cRYeC6oT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_checkpoint(model):\n",
        "\n",
        "    model.class_to_idx = training_dataset.class_to_idx\n",
        "\n",
        "    checkpoint = {'arch': \"vgg16\",\n",
        "                  'class_to_idx': model.class_to_idx,\n",
        "                  'model_state_dict': model.state_dict()\n",
        "                 }\n",
        "\n",
        "    torch.save(checkpoint, 'check.pth')\n",
        "    \n",
        "save_checkpoint(model)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G11VHl7f8bK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}